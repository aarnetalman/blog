<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Analysing News Article Content with Google Cloud Natural Language API | Aarne Talman</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Analysing News Article Content with Google Cloud Natural Language API" />
<meta name="author" content="Aarne Talman" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Demo on How to Use Google Cloud Natural Language and AI Platform Notebooks" />
<meta property="og:description" content="Demo on How to Use Google Cloud Natural Language and AI Platform Notebooks" />
<link rel="canonical" href="https://talman.fi/gcp/nlp/demo/2021/03/05/google-cloud-natural-language-api-demo.html" />
<meta property="og:url" content="https://talman.fi/gcp/nlp/demo/2021/03/05/google-cloud-natural-language-api-demo.html" />
<meta property="og:site_name" content="Aarne Talman" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-03-05T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"https://talman.fi/gcp/nlp/demo/2021/03/05/google-cloud-natural-language-api-demo.html","@type":"BlogPosting","headline":"Analysing News Article Content with Google Cloud Natural Language API","dateModified":"2021-03-05T00:00:00-06:00","datePublished":"2021-03-05T00:00:00-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://talman.fi/gcp/nlp/demo/2021/03/05/google-cloud-natural-language-api-demo.html"},"author":{"@type":"Person","name":"Aarne Talman"},"description":"Demo on How to Use Google Cloud Natural Language and AI Platform Notebooks","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://talman.fi/feed.xml" title="Aarne Talman" /><!-- the google_analytics_id gets auto inserted from the config file -->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-KNGC46YL32"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-KNGC46YL32');
</script>


<link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Aarne Talman</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a><a class="page-link" href="/code/">Code</a><a class="page-link" href="/publications/">Publications and Talks</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a><a class="page-link" href="/teaching/">Teaching</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Analysing News Article Content with Google Cloud Natural Language API</h1><p class="page-description">Demo on How to Use Google Cloud Natural Language and AI Platform Notebooks</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-03-05T00:00:00-06:00" itemprop="datePublished">
        Mar 5, 2021
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Aarne Talman</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      10 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#GCP">GCP</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#NLP">NLP</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#demo">demo</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/aarnetalman/blog/tree/master/_notebooks/2021-03-05-google-cloud-natural-language-api-demo.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          
          <div class="px-2">
    <a href="https://colab.research.google.com/github/aarnetalman/blog/blob/master/_notebooks/2021-03-05-google-cloud-natural-language-api-demo.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-03-05-google-cloud-natural-language-api-demo.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><em>This is a slightly modified version of an article originally posted on <a href="https://medium.com/nordcloud-engineering/analysing-news-article-content-with-google-cloud-natural-language-api-69f927aae85f">Nordcloud Engineering blog</a>.</em></p>
<p>In my <a href="https://talman.io/2021/02/25/training-transformer-model-gcp-ai-platform.html">previous blog post</a> I showed how to use AI Platform Training to fine-tune a custom NLP model using PyTorch and the <code>transformers</code> library. In this post we take advantage of Google's pre-trained AI models for NLP and use <a href="https://cloud.google.com/natural-language/docs">Cloud Natural Language API</a> to analyse text. Google's pre-trained machine learning APIs are great for building working AI prototypes and proof of concepts in matter of hours.</p>
<p>Google's Cloud Natural Language API allows you to do named entity recognition, sentiment analysis, content classification and syntax analysis using a simple REST API. The API supports Python, Go, Java, Node.js, Ruby, PHP and C#. In this post we'll be using the Python API.</p>
<p><img src="https://talman.io/images/paper.jpg" alt="Newspapers" /></p>
<p>Before we jump in, let's define our use case. To highlight the simplicity and power of the API I'm going to use it to analyse the content of news articles. In particular I want to find out if the latest articles published in The Guardian's world news section contain mentions of famous people and if those mentions have a positive or a negative sentiment. I also want to find out the overall sentiment of the news articles. To do this, we will go through a number of steps.</p>
<ol>
<li>We will use the Guardian's RSS feed to extract links to the latest news articles in the world news section.</li>
<li>We will download the HTML content of the articles published in the past 24 hours and extract the article text in plain text.</li>
<li>We will analyse the overall sentiment of the text using Cloud Natural Language.</li>
<li>We will extract named entities from the text using Cloud Natural Language.</li>
<li>We will go through all named entities of type <code>PERSON</code> and see if they have a Wikipedia entry (for the purposes of this post, this will be our measure of the person being "famous").</li>
<li>Once we've identified all the mentions of "famous people", we analyse the sentiment of the sentences mentioning them.</li>
<li>Finally, we will print the names, Wikipedia links and the sentiments of the mentions of all the "famous people" in each article, together with the article title, url and the overall sentiment of the article.</li>
</ol>
<p>We will do all this using Google Cloud AI Platform Notebooks.</p>
<p>To launch a new notebook make sure you are logged in to Google Cloud Console and have an active project selected. Navigate to AI Platform Notebooks and select <strong>New Instance</strong>. For this demo you don't need a very powerful notebook instance, so we will make some changes to the defaults to save cost. First, select <strong>Python 3</strong> (without CUDA) from the list and give a name for your notebook. Next, click the edit icon next to <strong>Instance properties</strong>. From Instance properties select n1-standard-1 as the Machine type. You'll see that the estimated cost of running this instance is only $0.041 per hour.</p>
<p><img src="https://talman.io/images/instance-type.png" alt="Instance type" /></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Once you have created the instance and it is running, click the Open JupyterLab link of your notebook instance. Once you're in JupyterLab, select new Python 3 notebook.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Steps-1-2:-Extract-the-Latest-News-Articles">Steps 1-2: Extract the Latest News Articles<a class="anchor-link" href="#Steps-1-2:-Extract-the-Latest-News-Articles"> </a></h2><p>We start start by downloading some required Python libraries. The following command uses pip to install lxml, Beautiful Soup and Feedparser. We use lxml and Beautiful Soup for processing and parsing HTML the content. Feedparser will be used to parse the RSS feed to identify the latest news articles and to get the links to the full text of those articles.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install lxml bs4 feedparser
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Once we have installed the required libraries we need to import them together with the other libraries we need for extracting the news article content.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">from</span> <span class="nn">bs4.element</span> <span class="kn">import</span> <span class="n">Comment</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">feedparser</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, we will define the url to the RSS feed as well as the time period we want to limit our search to.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">feed</span> <span class="o">=</span> <span class="s2">&quot;https://www.theguardian.com/world/rss&quot;</span>
<span class="n">days</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We will then define two functions we will use to extract the main article text from the HTML document. The <code>text_from_html</code> function will parse the HTML file, extract the text from that file and use the <code>tag_visible</code> function to filter out all but the main article text.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">tag_visible</span><span class="p">(</span><span class="n">element</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">element</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;p&#39;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">element</span><span class="p">,</span> <span class="n">Comment</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="kc">False</span>


<span class="k">def</span> <span class="nf">text_from_html</span><span class="p">(</span><span class="n">html</span><span class="p">):</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">html</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="s1">&#39;lxml&#39;</span><span class="p">)</span>
    <span class="n">texts</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">findAll</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">visible_texts</span> <span class="o">=</span> <span class="nb">filter</span><span class="p">(</span><span class="n">tag_visible</span><span class="p">,</span> <span class="n">texts</span><span class="p">)</span>  
    <span class="k">return</span> <span class="sa">u</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">visible_texts</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Once we have defined these functions we will parse the RSS feed, identify the articles published in the past 24 hours and extract the required attributes for those articles. We will need the article title, link, publishing time and, using the functions defined above, the plain text version of the article text.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">newsfeed</span> <span class="o">=</span> <span class="n">feedparser</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">feed</span><span class="p">)</span>
<span class="n">articles</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Get all the entries from within the last day</span>
<span class="n">entries</span> <span class="o">=</span> <span class="p">[</span><span class="n">entry</span> <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">newsfeed</span><span class="o">.</span><span class="n">entries</span> <span class="k">if</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">time</span><span class="o">.</span><span class="n">mktime</span><span class="p">(</span><span class="n">entry</span><span class="o">.</span><span class="n">published_parsed</span><span class="p">)</span> <span class="o">&lt;</span> <span class="p">(</span><span class="mi">86400</span><span class="o">*</span><span class="n">days</span><span class="p">)]</span>
<span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">entries</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">entries</span><span class="p">)):</span>
    <span class="n">html</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">entry</span><span class="o">.</span><span class="n">link</span><span class="p">)</span>             
    <span class="n">src_text</span> <span class="o">=</span> <span class="n">text_from_html</span><span class="p">(</span><span class="n">html</span><span class="p">)</span>             
    <span class="n">article</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">article</span><span class="p">[</span><span class="s2">&quot;title&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">entry</span><span class="o">.</span><span class="n">title</span>
    <span class="n">article</span><span class="p">[</span><span class="s2">&quot;link&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">entry</span><span class="o">.</span><span class="n">link</span>
    <span class="n">article</span><span class="p">[</span><span class="s2">&quot;src_text&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">src_text</span>
    <span class="n">article</span><span class="p">[</span><span class="s2">&quot;published&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">entry</span><span class="o">.</span><span class="n">published_parsed</span>
    <span class="n">articles</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">article</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Steps-3-7:-Analyse-the-Content-Using-Cloud-Natural-Language-API">Steps 3-7: Analyse the Content Using Cloud Natural Language API<a class="anchor-link" href="#Steps-3-7:-Analyse-the-Content-Using-Cloud-Natural-Language-API"> </a></h2><p>To use the Natural Language API we will import the required libraries.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">google.cloud</span> <span class="kn">import</span> <span class="n">language_v1</span>
<span class="kn">from</span> <span class="nn">google.cloud.language_v1</span> <span class="kn">import</span> <span class="n">enums</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, we define the main function for the demo. Below, in 21 lines of code, we will do all the needed text analysis as well as print the results to view the output. The function takes <code>document</code> as the input, analyses the contents and prints the results. We will look at the contents of the <code>document</code> input later.</p>
<p>To use the API we need to initialise the <code>LanguegeServiceClient</code>. We then define the encoding type which we need to pass together with the document to the API.</p>
<p>The first API call <code>analyze_entities(document, encoding_type=encoding_type)</code> takes the input document and the encoding type and returns a response of the following form:</p>
<div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="nt">&quot;entities&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="err">objec</span><span class="kc">t</span><span class="err">(E</span><span class="kc">nt</span><span class="err">i</span><span class="kc">t</span><span class="err">y)</span>
    <span class="p">}</span>
  <span class="p">],</span>
  <span class="nt">&quot;language&quot;</span><span class="p">:</span> <span class="err">s</span><span class="kc">tr</span><span class="err">i</span><span class="kc">n</span><span class="err">g</span>
<span class="p">}</span>
</pre></div>
<p>We will then call the API to analyse the sentiment of the document as well as to get the sentiments of each sentence in the document. The response has the following form:</p>
<div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="nt">&quot;documentSentiment&quot;</span><span class="p">:</span> <span class="p">{</span>
    <span class="err">objec</span><span class="kc">t</span><span class="err">(Se</span><span class="kc">nt</span><span class="err">ime</span><span class="kc">nt</span><span class="err">)</span>
  <span class="p">},</span>
  <span class="nt">&quot;language&quot;</span><span class="p">:</span> <span class="err">s</span><span class="kc">tr</span><span class="err">i</span><span class="kc">n</span><span class="err">g</span><span class="p">,</span>
  <span class="nt">&quot;sentences&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="err">objec</span><span class="kc">t</span><span class="err">(Se</span><span class="kc">nten</span><span class="err">ce)</span>
    <span class="p">}</span>
  <span class="p">]</span>
<span class="p">}</span>
</pre></div>
<p>The overall document sentiment is stored in <code>annotations.document_sentiment.score</code>. We assign the document an overall sentiment POSITIVE if the score is above 0, NEGATIVE if it is less than 0 and NEUTRAL if it is 0.</p>
<p>We then go through all the entities identified by the API and create a list of those entities that have the type PERSON. Once we have this list, we loop through it and check which ones from the list have <code>wikipedia_url</code> in their <code>metadata_name</code>. As said, we use this as our measure of the person being "famous". When we identify a "famous person" we print the person's name and the link to the Wikipedia entry.</p>
<p>We then check the sentiment annotated sentences for occurrence of the identified "famous people" and use the same values as above to determine the sentiment category of those sentences. Finally, we print all the sentiments of all the sentences mentioning the person.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">print_sentiments</span><span class="p">(</span><span class="n">document</span><span class="p">):</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">language_v1</span><span class="o">.</span><span class="n">LanguageServiceClient</span><span class="p">()</span>
    <span class="n">encoding_type</span> <span class="o">=</span> <span class="n">enums</span><span class="o">.</span><span class="n">EncodingType</span><span class="o">.</span><span class="n">UTF8</span>
    
    <span class="c1"># Get entities from the document</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">analyze_entities</span><span class="p">(</span><span class="n">document</span><span class="p">,</span> <span class="n">encoding_type</span><span class="o">=</span><span class="n">encoding_type</span><span class="p">)</span>
    <span class="c1"># Get sentiment annontations from the document</span>
    <span class="n">annotations</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">analyze_sentiment</span><span class="p">(</span><span class="n">document</span><span class="p">,</span> <span class="n">encoding_type</span><span class="o">=</span><span class="n">encoding_type</span><span class="p">)</span>
    <span class="c1"># Get overall document sentiment score</span>
    <span class="n">overall_sentiment</span> <span class="o">=</span> <span class="s1">&#39;POSITIVE&#39;</span> <span class="k">if</span> <span class="n">annotations</span><span class="o">.</span><span class="n">document_sentiment</span><span class="o">.</span><span class="n">score</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="s1">&#39;NEGATIVE&#39;</span> \
                    <span class="k">if</span> <span class="n">annotations</span><span class="o">.</span><span class="n">document_sentiment</span><span class="o">.</span><span class="n">score</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="s1">&#39;NEUTRAL&#39;</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Overall sentiment: </span><span class="si">{</span><span class="n">overall_sentiment</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="c1"># Construct a list of entities where the entity type is a PERSON</span>
    <span class="n">entities</span> <span class="o">=</span> <span class="p">[</span><span class="n">entity</span> <span class="k">for</span> <span class="n">entity</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">entities</span> <span class="k">if</span> <span class="n">enums</span><span class="o">.</span><span class="n">Entity</span><span class="o">.</span><span class="n">Type</span><span class="p">(</span><span class="n">entity</span><span class="o">.</span><span class="n">type</span><span class="p">)</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;PERSON&#39;</span><span class="p">]</span>
    
    <span class="c1"># Loop through persons</span>
    <span class="k">for</span> <span class="n">entity</span> <span class="ow">in</span> <span class="n">entities</span><span class="p">:</span>
        <span class="c1"># Check if the entity has a metadata entry containing a wikipedia link</span>
        <span class="k">for</span> <span class="n">metadata_name</span><span class="p">,</span> <span class="n">metadata_value</span> <span class="ow">in</span> <span class="n">entity</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">metadata_name</span> <span class="o">==</span> <span class="s1">&#39;wikipedia_url&#39;</span><span class="p">:</span>
                <span class="n">name</span> <span class="o">=</span> <span class="n">entity</span><span class="o">.</span><span class="n">name</span>
                <span class="n">wiki_url</span> <span class="o">=</span> <span class="n">metadata_value</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Person: </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;- Wikipedia: </span><span class="si">{</span><span class="n">wiki_url</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                
                <span class="c1"># Get all sentences mentioning the person</span>
                <span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="n">sentence</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">annotations</span><span class="o">.</span><span class="n">sentences</span> <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">content</span><span class="p">]</span>
                
                <span class="c1"># Display whether the sentences mentioning the person are negative, positive or neutral</span>
                <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sentences</span><span class="p">):</span>
                    <span class="n">sentence_sentiment</span> <span class="o">=</span> <span class="s1">&#39;POSITIVE&#39;</span> <span class="k">if</span> <span class="n">sentence</span><span class="o">.</span><span class="n">sentiment</span><span class="o">.</span><span class="n">score</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="s1">&#39;NEGATIVE&#39;</span> \
                    <span class="k">if</span> <span class="n">sentence</span><span class="o">.</span><span class="n">sentiment</span><span class="o">.</span><span class="n">score</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="s1">&#39;NEUTRAL&#39;</span>
                    
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;- Sentence: </span><span class="si">{</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s2"> mentioning </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> is: </span><span class="si">{</span><span class="n">sentence_sentiment</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we have extracted the text from the news site and defined the function to analyse the contents of each article, all we need to do is go through the articles and call the function. The input for the function is a dictionary containing the plain text contents of the article, the type of the document (which in our case if <code>PLAIN_TEXT</code>) and the language of the document (which for us is English). We also print the name of each article and the link to the article.</p>
<p>For demo purposes we limit our analysis to the first 3 articles.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">language</span> <span class="o">=</span> <span class="s2">&quot;en&quot;</span>
<span class="n">type_</span> <span class="o">=</span> <span class="n">enums</span><span class="o">.</span><span class="n">Document</span><span class="o">.</span><span class="n">Type</span><span class="o">.</span><span class="n">PLAIN_TEXT</span>

<span class="c1"># Analyse the latest 5 articles </span>
<span class="k">for</span> <span class="n">article</span> <span class="ow">in</span> <span class="n">articles</span><span class="p">[:</span><span class="mi">3</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;#&#39;</span><span class="o">*</span><span class="mi">50</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">article</span><span class="p">[</span><span class="s2">&quot;title&quot;</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">article</span><span class="p">[</span><span class="s2">&quot;link&quot;</span><span class="p">])</span>
    <span class="n">document</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">article</span><span class="p">[</span><span class="s2">&quot;src_text&quot;</span><span class="p">],</span> <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="n">type_</span><span class="p">,</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="n">language</span><span class="p">}</span>
    <span class="n">print_sentiments</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>  
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;#&#39;</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

<pre><code>##################################################

‘We have to win’: Myanmar protesters persevere as forces ramp up violence
https://www.theguardian.com/world/2021/feb/28/we-have-to-win-myanmar-protesters-persevere-as-forces-ramp-up-violence
Overall sentiment: NEGATIVE

Person: Min Aung Hlaing
- Wikipedia: https://en.wikipedia.org/wiki/Min_Aung_Hlaing
- Sentence: 1 mentioning Min Aung Hlaing is: NEUTRAL

Person: Aung San Suu Kyi
- Wikipedia: https://en.wikipedia.org/wiki/Aung_San_Suu_Kyi
- Sentence: 1 mentioning Aung San Suu Kyi is: POSITIVE

##################################################

White House defends move not to sanction Saudi crown prince
https://www.theguardian.com/world/2021/feb/28/white-house-defends-not-sanction-saudi-crown-prince-khashoggi-killing
Overall sentiment: NEGATIVE

Person: Joe Biden
- Wikipedia: https://en.wikipedia.org/wiki/Joe_Biden
- Sentence: 1 mentioning Joe Biden is: NEGATIVE

Person: Mark Warner
- Wikipedia: https://en.wikipedia.org/wiki/Mark_Warner
- Sentence: 1 mentioning Mark Warner is: NEGATIVE

Person: Khashoggi
- Wikipedia: https://en.wikipedia.org/wiki/Jamal_Khashoggi
- Sentence: 1 mentioning Khashoggi is: NEGATIVE
- Sentence: 2 mentioning Khashoggi is: NEGATIVE
- Sentence: 3 mentioning Khashoggi is: NEGATIVE

Person: Jen Psaki
- Wikipedia: https://en.wikipedia.org/wiki/Jen_Psaki
- Sentence: 1 mentioning Jen Psaki is: NEGATIVE

Person: Democrats
- Wikipedia: https://en.wikipedia.org/wiki/Democratic_Party_(United_States)
- Sentence: 1 mentioning Democrats is: NEGATIVE

Person: Gregory Meeks
- Wikipedia: https://en.wikipedia.org/wiki/Gregory_Meeks
- Sentence: 1 mentioning Gregory Meeks is: POSITIVE

Person: Prince Mohammed
- Wikipedia: https://en.wikipedia.org/wiki/Mohammed_bin_Salman
- Sentence: 1 mentioning Prince Mohammed is: NEGATIVE

##################################################

Coronavirus live news: South Africa lowers alert level; Jordan ministers sacked for breaches
https://www.theguardian.com/world/live/2021/feb/28/coronavirus-live-news-us-approves-johnson-johnson-vaccine-auckland-starts-second-lockdown-in-a-month
Overall sentiment: NEGATIVE

Person: Germany
- Wikipedia: https://en.wikipedia.org/wiki/Germany
- Sentence: 1 mentioning Germany is: NEGATIVE
- Sentence: 2 mentioning Germany is: NEUTRAL

Person: Nick Thomas-Symonds
- Wikipedia: https://en.wikipedia.org/wiki/Nick_Thomas-Symonds
- Sentence: 1 mentioning Nick Thomas-Symonds is: NEGATIVE

Person: Cyril Ramaphosa
- Wikipedia: https://en.wikipedia.org/wiki/Cyril_Ramaphosa
- Sentence: 1 mentioning Cyril Ramaphosa is: NEGATIVE

Person: Raymond Johansen
- Wikipedia: https://en.wikipedia.org/wiki/Raymond_Johansen
- Sentence: 1 mentioning Raymond Johansen is: NEGATIVE

Person: Archie Bland
- Wikipedia: https://en.wikipedia.org/wiki/Archie_Bland
- Sentence: 1 mentioning Archie Bland is: NEUTRAL

##################################################</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As you can see the 3 articles we analysed all have an overall negative sentiment. We also found quite a few mentions of people with Wikipedia entries as well as the sentiments of those sentences.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Conclusion">Conclusion<a class="anchor-link" href="#Conclusion"> </a></h2><p>As we saw, the Cloud Natural Language API is super simple and powerful tool that allows us to analyse text with just a few lines of code. This is great when you are working on a new use case and you need to quickly test the feasibility of an AI-based solution. It is also the go-to resource when you don't have data to train your own machine learning model for the task. However, if you need to create a more custom model for your use case, I recommend using <a href="https://cloud.google.com/natural-language/automl/docs">AutoML Natural Language</a> or training your own model using AI Platform Training.</p>
<p>Hope you enjoyed this demo. Feel free to contact me if you have any questions.</p>
<ul>
<li>Twitter: <a href="https://twitter.com/aarnetalman">@AarneTalman</a></li>
<li>Website: <a href="https://talman.io">talman.io</a></li>
</ul>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="aarnetalman/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/gcp/nlp/demo/2021/03/05/google-cloud-natural-language-api-demo.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Natural Language Processing and Machine Learning</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/aarnetalman" title="aarnetalman"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/aarnetalman" title="aarnetalman"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
