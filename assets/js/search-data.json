{
  
    
        "post0": {
            "title": "Training Transformer Model Gcp Ai Platform",
            "content": "Training PyTorch Transformers on GCP AI Platform . Demo on how to train a state-of-the-art sequence classification model on Google Cloud Platform . toc: false | comments: true | author: Aarne Talman | categories: [cloud, gcp, python, demo] | . Google Cloud Platform (GCP) is widely known for its great AI and machine learning capabilities and products. In fact there are tons of material available on how you can train and deploy TensorFlow models on GCP. However, GCP is not just for people using TensorFlow. It has good support for other frameworks as well. In this post I will show how to use another highly popular ML framework PyTorch on AI Platform Training. I will show how to fine-tune a state-of-the-art sequence classification model using PyTorch and the transformers library. We will be using a pre-trained RoBERTa as the transformer model for this task. . This post covers the following topics: . How to structure your ML project for AI Platform Training | Code for the model, the training routine and evaluation of the model | How to launch and monitor your training job | . You can find all the code in this GitHub repo: . ML Project Structure . Let’s start with the contents of our ML project. . ├── trainer/ │ ├── __init__.py │ ├── experiment.py │ ├── inputs.py │ ├── model.py │ └── task.py ├── scripts/ │ └── train-gcp.sh ├── config.yaml └── setup.py . The trainer directory contains all the python files required to train the model. The contents of this directory will be packaged and submitted to AI platform. You can find more details and best practices on how to package your training application here. We will look at the contents of the individual files later in this post. . The scripts directory contains our training scripts that will configure the required environment variables and submit the job to AI Platform Training. . config.yaml contains configuration of the compute instance used for training the model. Finally, setup.pycontains details about our python package and the required dependencies. AI Platform Training will use the details in this file to install any missing dependencies before starting the training job. . PyTorch Code for Training the Model . Let’s look at the contents of our python package. the first one, __init__.py is just an empty file. This needs to be in place and located in each subdirectory. The init files will be used by Python Setuptools to identify directories with code to package. It is OK to leave this file empty. . The rest of the files contain different parts of our PyTorch software. task.py is our main file and will be called by AI Platform Training. It retrieves the command line arguments for our training task and passes those to the run function in experiment.py. The contents of task.py are below. . def get_args(): &quot;&quot;&quot;Define the task arguments with the default values. Returns: experiment parameters &quot;&quot;&quot; parser = ArgumentParser(description=&#39;NLI with Transformers&#39;) parser.add_argument(&#39;--batch_size&#39;, type=int, default=16) parser.add_argument(&#39;--epochs&#39;, type=int, default=2) parser.add_argument(&#39;--log_every&#39;, type=int, default=50) parser.add_argument(&#39;--learning_rate&#39;, type=float, default=0.00005) parser.add_argument(&#39;--fraction_of_train_data&#39;, type=float, default=1 ) parser.add_argument(&#39;--seed&#39;, type=int, default=1234) parser.add_argument(&#39;--weight-decay&#39;, default=0, type=float) parser.add_argument(&#39;--job-dir&#39;, help=&#39;GCS location to export models&#39;) parser.add_argument(&#39;--model-name&#39;, help=&#39;The name of your saved model&#39;, default=&#39;model.pth&#39;) return parser.parse_args() def main(): &quot;&quot;&quot;Setup / Start the experiment &quot;&quot;&quot; args = get_args() experiment.run(args) if __name__ == &#39;__main__&#39;: main() . Before we look at the main training and evaluation routines, let’s look at the inputs.py and model.py which define the datasets for the task and the transformer model respectively. First, the we use the datasets library to retrieve our data for the experiment. We use the MultiNLI sequence classification dataset for this experiment. The inputs.py file contains code to retrieve, split and pre-process the data. The NLIDataset provides the PyTorch Dataset object for the training, development and test data for our task. . class NLIDataset(torch.utils.data.Dataset): def __init__(self, encodings, labels): self.encodings = encodings self.labels = labels def __getitem__(self, idx): item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()} item[&#39;labels&#39;] = torch.tensor(self.labels[idx]) return item def __len__(self): #return len(self.labels) return len(self.encodings.input_ids) . The load_data function retrieves the data using the datasets library, splits the data into training, development and test sets, and then tokenises the input using RobertaTokenizer and creates PyTorch DataLoader objects for the different sets. . def load_data(args): tokenizer = RobertaTokenizer.from_pretrained(&#39;roberta-base&#39;) nli_data = datasets.load_dataset(&#39;multi_nli&#39;) # For testing purposes get a slammer slice of the training data all_examples = len(nli_data[&#39;train&#39;][&#39;label&#39;]) num_examples = int(round(all_examples * args.fraction_of_train_data)) print(&quot;Training with {}/{} examples.&quot;.format(num_examples, all_examples)) train_dataset = nli_data[&#39;train&#39;][:num_examples] dev_dataset = nli_data[&#39;validation_matched&#39;] test_dataset = nli_data[&#39;validation_matched&#39;] train_labels = train_dataset[&#39;label&#39;] val_labels = dev_dataset[&#39;label&#39;] test_labels = test_dataset[&#39;label&#39;] train_encodings = tokenizer(train_dataset[&#39;premise&#39;], train_dataset[&#39;hypothesis&#39;], truncation=True, padding=True) val_encodings = tokenizer(dev_dataset[&#39;premise&#39;], dev_dataset[&#39;hypothesis&#39;], truncation=True, padding=True) test_encodings = tokenizer(test_dataset[&#39;premise&#39;], test_dataset[&#39;hypothesis&#39;], truncation=True, padding=True) train_dataset = NLIDataset(train_encodings, train_labels) val_dataset = NLIDataset(val_encodings, val_labels) test_dataset = NLIDataset(test_encodings, test_labels) train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True) dev_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=True) test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=True) return train_loader, dev_loader, test_loader . The save_model function will save the trained model once it’s been trained and uploads it to Google Cloud Storage. . def save_model(args): &quot;&quot;&quot;Saves the model to Google Cloud Storage Args: args: contains name for saved model. &quot;&quot;&quot; scheme = &#39;gs://&#39; bucket_name = args.job_dir[len(scheme):].split(&#39;/&#39;)[0] prefix = &#39;{}{}/&#39;.format(scheme, bucket_name) bucket_path = args.job_dir[len(prefix):].rstrip(&#39;/&#39;) datetime_ = datetime.datetime.now().strftime(&#39;model_%Y%m%d_%H%M%S&#39;) if bucket_path: model_path = &#39;{}/{}/{}&#39;.format(bucket_path, datetime_, args.model_name) else: model_path = &#39;{}/{}&#39;.format(datetime_, args.model_name) bucket = storage.Client().bucket(bucket_name) blob = bucket.blob(model_path) blob.upload_from_filename(args.model_name) . The model.py file contains code for the transformer model RoBERTa. The create function initialises the model and the optimiser. . # Specify the Transformer model class RoBERTaModel(nn.Module): def __init__(self): &quot;&quot;&quot;Defines the transformer model to be used. &quot;&quot;&quot; super(RoBERTaModel, self).__init__() self.model = RobertaForSequenceClassification.from_pretrained(&#39;roberta-base&#39;, num_labels=3) def forward(self, x, attention_mask, labels): return self.model(x, attention_mask=attention_mask, labels=labels) def create(args, device): &quot;&quot;&quot; Create the model Args: args: experiment parameters. device: device. &quot;&quot;&quot; model = RoBERTaModel().to(device) optimizer = optim.Adam(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay) return model, optimizer . The experiment.py file contains the main training and evaluation routines for our task. It contains the functions train, evaluate and run. The train function takes our training dataloader as an input and trains the model for one epoch in batches of the size defined in the command line arguments. . def train(args, model, dataloader, optimizer, device): &quot;&quot;&quot;Create the training loop for one epoch. Args: model: The transformer model that you are training, based on nn.Module dataloader: The training dataset optimizer: The selected optmizer to update parameters and gradients device: device &quot;&quot;&quot; model.train() for i, batch in enumerate(dataloader): optimizer.zero_grad() input_ids = batch[&#39;input_ids&#39;].to(device) attention_mask = batch[&#39;attention_mask&#39;].to(device) labels = batch[&#39;labels&#39;].to(device) outputs = model(input_ids, attention_mask=attention_mask, labels=labels) loss = outputs[0] loss.backward() optimizer.step() if i == 0 or i % args.log_every == 0 or i+1 == len(dataloader): print(&quot;Progress: {:3.0f}% - Batch: {:&gt;4.0f}/{:&lt;4.0f} - Loss: {:&lt;.4f}&quot;.format( 100. * (1+i) / len(dataloader), # Progress i+1, len(dataloader), # Batch loss.item())) # Loss . The evaluate function takes the development or test dataloader as an input and evaluates the prediction accuracy of our model. This will be called after each training epoch using the development dataloader and after the training has finished using the test dataloader. . def evaluate(model, dataloader, device): &quot;&quot;&quot;Create the evaluation loop. Args: model: The transformer model that you are training, based on nn.Module dataloader: The development or testing dataset device: device &quot;&quot;&quot; print(&quot; nStarting evaluation...&quot;) model.eval() with torch.no_grad(): eval_preds = [] eval_labels = [] for _, batch in enumerate(dataloader): input_ids = batch[&#39;input_ids&#39;].to(device) attention_mask = batch[&#39;attention_mask&#39;].to(device) labels = batch[&#39;labels&#39;].to(device) preds = model(input_ids, attention_mask=attention_mask, labels=labels) preds = preds[1].argmax(dim=-1) eval_preds.append(preds.cpu().numpy()) eval_labels.append(batch[&#39;labels&#39;].cpu().numpy()) print(&quot;Done evaluation&quot;) return np.concatenate(eval_labels), np.concatenate(eval_preds) . Finally, the run function calls the run and evaluate functions and saves the fine-tuned model to Google Cloud Storage once training has completed. . def run(args): &quot;&quot;&quot;Load the data, train, evaluate, and export the model for serving and evaluating. Args: args: experiment parameters. &quot;&quot;&quot; cuda_availability = torch.cuda.is_available() if cuda_availability: device = torch.device(&#39;cuda:{}&#39;.format(torch.cuda.current_device())) else: device = &#39;cpu&#39; print(&#39; n*************************&#39;) print(&#39;`cuda` available: {}&#39;.format(cuda_availability)) print(&#39;Current Device: {}&#39;.format(device)) print(&#39;************************* n&#39;) torch.manual_seed(args.seed) # Open our dataset train_loader, eval_loader, test_loader = inputs.load_data(args) # Create the model, loss function, and optimizer bert_model, optimizer = model.create(args, device) # Train / Test the model for epoch in range(1, args.epochs + 1): train(args, bert_model, train_loader, optimizer, device) dev_labels, dev_preds = evaluate(bert_model, eval_loader, device) # Print validation accuracy dev_accuracy = (dev_labels == dev_preds).mean() print(&quot; nDev accuracy after epoch {}: {}&quot;.format(epoch, dev_accuracy)) # Evaluate the model print(&quot;Evaluate the model using the testing dataset&quot;) test_labels, test_preds = evaluate(bert_model, test_loader, device) # Print validation accuracy test_accuracy = (test_labels == test_preds).mean() print(&quot; nTest accuracy after epoch {}: {}&quot;.format(args.epochs, test_accuracy)) # Export the trained model torch.save(bert_model.state_dict(), args.model_name) # Save the model to GCS if args.job_dir: inputs.save_model(args) . Launching and monitoring the training job . Once we have the python code for our training job, we need to prepare it for AI Platform Training. There are three important files required for this. First, setup.py contains information about the dependencies of our python package as well as metadata like name and version of the package. . from setuptools import find_packages from setuptools import setup REQUIRED_PACKAGES = [ &#39;google-cloud-storage&gt;=1.14.0&#39;, &#39;transformers&#39;, &#39;datasets&#39;, &#39;numpy==1.18.5&#39;, &#39;argparse&#39;, &#39;tqdm==4.49.0&#39; ] setup( name=&#39;trainer&#39;, version=&#39;0.1&#39;, install_requires=REQUIRED_PACKAGES, packages=find_packages(), include_package_data=True, description=&#39;Sequence Classification with Transformers on GCP AI Platform&#39; ) . The config.yaml file contains information about the compute instance used for training the model. For this job we need use an NVIDIA V100 GPU as it provides improved training speed and larger GPU memory compared to the cheaper K80 GPUs. . trainingInput: scaleTier: CUSTOM masterType: n1-standard-8 masterConfig: acceleratorConfig: count: 1 type: NVIDIA_TESLA_V100 . Finally the scripts directory contains the train-gcp.sh script which includes the required environment variables as will as the gcloud command to submit the AI Platform Training job. . # BUCKET_NAME: unique bucket name BUCKET_NAME=-name-of-your-gs-bucket # The PyTorch image provided by AI Platform Training. IMAGE_URI=gcr.io/cloud-ml-public/training/pytorch-gpu.1-4 # JOB_NAME: the name of your job running on AI Platform. JOB_NAME=transformers_job_$(date +%Y%m%d_%H%M%S) echo &quot;Submitting AI Platform Training job: ${JOB_NAME}&quot; PACKAGE_PATH=./trainer # this can be a GCS location to a zipped and uploaded package REGION=us-central1 # JOB_DIR: Where to store prepared package and upload output model. JOB_DIR=gs://${BUCKET_NAME}/${JOB_NAME}/models gcloud ai-platform jobs submit training ${JOB_NAME} --region ${REGION} --master-image-uri ${IMAGE_URI} --config config.yaml --job-dir ${JOB_DIR} --module-name trainer.task --package-path ${PACKAGE_PATH} -- --epochs 2 --batch_size 16 --learning_rate 2e-5 . To monitor the training job you can stream the logs using gcloud: . gcloud ai-platform jobs stream-logs ${JOB_NAME} . Alternatively you can head to GCP console and navigate to AI Platform jobs and select View logs. You can also view the GPU utilisation and memory from the AI Platform job page. . Conclusion . That concludes this post. You can find all the code on Github. . Hope you enjoyed this demo. Feel free to contact me if you have any questions. . Twitter: @AarneTalman | Website: talman.io | .",
            "url": "https://talman.io/2021/02/23/training-transformer-model-gcp-ai-platform.html",
            "relUrl": "/2021/02/23/training-transformer-model-gcp-ai-platform.html",
            "date": " • Feb 23, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Simple Bag-of-Words Search Engine in Python",
            "content": "In my previous post I showed how to build a simple semantic search engine using pre-trained transformer models. . In this post I&#39;ll show how to build a simple search engine using Python and the BM25 ranking algorithm. BM25 is a bag-of-words ranking function designed for information retrieval. It is an enhanced version of the term frequency–inverse document frequency (tf-idf) method. . The basic idea behind tf-idf is that it looks at the frequency of the term in the document (more the better) and it looks at the inverse document frequency (common words are less important). One of the drawbacks of the standard tf-idf is that long documents with the same term frequency are considered less important. . BM25 makes couple of enhancements to the traditional tf-idf. First, BM25 adds a term frequency saturation to tf-idf, limiting the influence of term frequency on the score. Intuitively this means that more frequent the term is the less impact each occurence of it has on the score. Second, BM25 adds a document length weighting, which makes sure that document length doesn&#39;t have such a dramatic negative impact on the relevance score as in tf-idf. . Building a BM25-based search engine with Python is easy. There&#39;s a great library rank-bm25 which implements the scoring algorithm. To demonstrate the use of this library I&#39;m going to build a simple search engine that retrieves article abstracts from arXiv and searches for the most relevant articles based on a given search term. So, let&#39;s get started. . Let&#39;s first install and import the needed Python libraries. . !pip install rank_bm25 nltk numpy feedparser . from rank_bm25 import BM25Okapi import re import nltk from nltk.corpus import stopwords from nltk.tokenize import word_tokenize import numpy as np import feedparser import time . We will use NLTK to tokenize the documents and to identify stopwords, so we need to download the relevant data files used by NLTK. . nltk.download(&#39;stopwords&#39;) nltk.download(&#39;punkt&#39;) . Next we retrieve the documents from arXiv. For this we use the arXiv API. We download 10,000 abstracts from arXiv&#39;s Computation and Language (cs.CL) category. The arXiv API returns an Atom feed which we can parse using the feedparser library. This gives us an easy access to the article titles, abstracts, links to the full texts as well as many other useful attributes. Parsing the 10,000 entries will take a couple of minutes. . num_docs = 10000 url = f&quot;http://export.arxiv.org/api/query?search_query=cat:cs.CL&amp;start=0&amp;max_results={str(num_docs)}&quot; feed = feedparser.parse(url) . Next we remove any special characters, tokenise the article abstracts and remove any stopwords. . stop_words = list(stopwords.words(&#39;english&#39;)) tokenized_docs = [] for doc in feed.entries: # Article abstracts are stored in entries[i].summary doc = str(doc.summary).lower() doc = re.sub(r&quot;([ w].)([ ~ ! @ # $ % ^ &amp; * ( ) - + [ ] { } / &quot; &#39; : ;])([ s w].)&quot;, &quot; 1 2 3&quot;, doc) doc = re.sub(r&quot; s+&quot;, &quot; &quot;, doc) doc = [token for token in word_tokenize(doc.lower()) if token not in stop_words and token.isalpha()] tokenized_docs.append(doc) . Now we can define the scoring function using the rank-mb25 library. This function takes the tokenized article abstracts (docs) and the tokenised search term. It also stores the indices for the scores so that we can later link the scores to the correct article. . def get_bm25_scores(tokenized_docs, query): bm25 = BM25Okapi(tokenized_docs) scores = bm25.get_scores(query) scores = [(i, v) for i, v in enumerate(scores)] scores.sort(key=lambda x: x[1], reverse=True) return scores . Now let&#39;s define our search term and ther number of results we want to retrieve. In this demo we will search for articles about Natural Language Inference and we want to retrieve the top 5 articles. . num_results = 5 search_term = &quot;Natural Language Inference&quot; . Next we tokenise the search term and call the ranking algorithm we defined earlier. . query = search_term.lower().split(&#39; &#39;) t0 = time.time() scores = get_bm25_scores(tokenized_docs, query) t1 = time.time() query_time = t1-t0 . Once we have the scores we can use the indices to identify the correct entries in the original data. . idx = np.array(scores)[:num_results, 0].astype(int) final_scores = np.array(scores)[:num_results, 1] documents = [feed.entries[i] for i in idx] . We now have the top 5 article entries together with their scores retrieved form 10,000 entries in the cs.CL category. Let&#39;s print out the titles, links to the full texts and the summaries. . print(f&quot;Searched {str(num_docs)} documents in {str(round(query_time, 3))} seconds n&quot;) # Article titles are stored in entries[i].title # Article abstracts are stored in entries[i].summary # Article links are stored in entries[i].link for doc, score in zip(documents, final_scores): print(f&quot;{doc.title} n{doc.link} n n{doc.summary} n[Score: {str(round(score, 4))}] n n&quot;) . Searched 10000 documents in 0.434 seconds Stochastic Answer Networks for Natural Language Inference http://arxiv.org/abs/1804.07888v2 We propose a stochastic answer network (SAN) to explore multi-step inference strategies in Natural Language Inference. Rather than directly predicting the results given the inputs, the model maintains a state and iteratively refines its predictions. Our experiments show that SAN achieves the state-of-the-art results on three benchmarks: Stanford Natural Language Inference (SNLI) dataset, MultiGenre Natural Language Inference (MultiNLI) dataset and Quora Question Pairs dataset. [Score: 8.8786] Attention Boosted Sequential Inference Model http://arxiv.org/abs/1812.01840v2 Attention mechanism has been proven effective on natural language processing. This paper proposes an attention boosted natural language inference model named aESIM by adding word attention and adaptive direction-oriented attention mechanisms to the traditional Bi-LSTM layer of natural language inference models, e.g. ESIM. This makes the inference model aESIM has the ability to effectively learn the representation of words and model the local subsentential inference between pairs of premise and hypothesis. The empirical studies on the SNLI, MultiNLI and Quora benchmarks manifest that aESIM is superior to the original ESIM model. [Score: 8.591] A Neural Architecture Mimicking Humans End-to-End for Natural Language Inference http://arxiv.org/abs/1611.04741v2 In this work we use the recent advances in representation learning to propose a neural architecture for the problem of natural language inference. Our approach is aligned to mimic how a human does the natural language inference process given two statements. The model uses variants of Long Short Term Memory (LSTM), attention mechanism and composable neural networks, to carry out the task. Each part of our model can be mapped to a clear functionality humans do for carrying out the overall task of natural language inference. The model is end-to-end differentiable enabling training by stochastic gradient descent. On Stanford Natural Language Inference(SNLI) dataset, the proposed model achieves better accuracy numbers than all published models in literature. [Score: 8.5675] Neural Natural Language Inference Models Enhanced with External Knowledge http://arxiv.org/abs/1711.04289v3 Modeling natural language inference is a very challenging task. With the availability of large annotated data, it has recently become feasible to train complex models such as neural-network-based inference models, which have shown to achieve the state-of-the-art performance. Although there exist relatively large annotated data, can machines learn all knowledge needed to perform natural language inference (NLI) from these data? If not, how can neural-network-based NLI models benefit from external knowledge and how to build NLI models to leverage it? In this paper, we enrich the state-of-the-art neural natural language inference models with external knowledge. We demonstrate that the proposed models improve neural NLI models to achieve the state-of-the-art performance on the SNLI and MultiNLI datasets. [Score: 8.2145] Baselines and test data for cross-lingual inference http://arxiv.org/abs/1704.05347v2 The recent years have seen a revival of interest in textual entailment, sparked by i) the emergence of powerful deep neural network learners for natural language processing and ii) the timely development of large-scale evaluation datasets such as SNLI. Recast as natural language inference, the problem now amounts to detecting the relation between pairs of statements: they either contradict or entail one another, or they are mutually neutral. Current research in natural language inference is effectively exclusive to English. In this paper, we propose to advance the research in SNLI-style natural language inference toward multilingual evaluation. To that end, we provide test data for four major languages: Arabic, French, Spanish, and Russian. We experiment with a set of baselines. Our systems are based on cross-lingual word embeddings and machine translation. While our best system scores an average accuracy of just over 75%, we focus largely on enabling further research in multilingual inference. [Score: 8.1544] . As you can see the BM25 algorithm works pretty well and the rank-bm25 Python library is able to rank 10,000 article abstracts in just 0.434 seconds. In this demo the most time consuming part was retrieving and parsing the 10,000 entries using feedparser. In real life applications you would index the data to allow faster retrieval. . Hope you enjoyed this demo. Feel free to contact me if you have any questions. . Twitter: @AarneTalman | Website: talman.io | .",
            "url": "https://talman.io/information_retrieval/python/demo/2020/12/30/simple-search-engine-with-bm25.html",
            "relUrl": "/information_retrieval/python/demo/2020/12/30/simple-search-engine-with-bm25.html",
            "date": " • Dec 30, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Semantic Search with Pre-trained Sentence Encoders",
            "content": "In the previous two posts I&#39;ve explored the HuggingFace Transformers library and demonstrated: . how to train a classification model for NLI . | how to use an NLI model to rank news articles based on a keyword . | In this post I will show how to use a pre-trained sentence encoder model to create a simple semantic search engine for website content. The search engine will be &quot;semantic&quot; in the sense that it will try to find sentences from the website whose vector representation &quot;matches&quot; the vector representation of the search term. . We will use a pre-trained transformers model to encode all the sentences of a website as well as the search term and then calculate the cosine similarity between each encoded sentence and the search term. We will then rank the sentences based on the cosine similarity. . Let&#39;s get started. As before we will first install the libraries we need for this demo. We are using a library called Sentence Transformers, which provides pre-trained transformers models specifically for the purpose of computing sentence-level vector representations. We also need to install scikit-learn, as we will use it to calculate the cosine similarities between sentence vectors. . !pip install sentence_transformers sklearn lxml bs4 . Once we have installed the liraries we will import them together with some other usefult librarires we will use in the demo. . from sentence_transformers import SentenceTransformer import numpy as np from sklearn.metrics.pairwise import cosine_similarity from bs4 import BeautifulSoup from bs4.element import Comment import requests from IPython.display import Markdown, display . As in the previous post we define some functions we will use for cleaning up the text from the website html as well as a function to print our output in markdown format. . def tag_visible(element): if element.parent.name in [&#39;p&#39;]: return True if isinstance(element, Comment): return False return False def text_from_html(html): soup = BeautifulSoup(html.content, &#39;lxml&#39;) texts = soup.findAll(text=True) visible_texts = filter(tag_visible, texts) return u&quot; &quot;.join(t.strip() for t in visible_texts) def printmd(string): display(Markdown(string)) . Now we can define the website we are interested in together with the search term. We also define how many search results we want to see. In this demo we are interested in finding top five sentences from the Deep Learning Wikipedia article that are about Natural Language Processing. . website = &#39;https://en.wikipedia.org/wiki/Deep_learning&#39; search_term = &#39;natural language processing&#39; num_results = 5 . We then retrieve and extract the text from the website and split the sentences to a list. . html = requests.get(website) src_text = text_from_html(html) input_text = src_text.split(&#39;.&#39;) . For our model we use the roberta-large-nli-stsb-mean-tokens model which according to the Sentence transformers Github page beats the other Sentence Transformer models in the Semantic Textual Similarity (STS) benchmark. . model = SentenceTransformer(&#39;roberta-base-nli-stsb-mean-tokens&#39;) . Next we encode the list of sentences retrieved from the website as well as the search term using the Sentence Transformer model. . encoded_text = np.array(model.encode(input_text)) encoded_query = np.array(model.encode([search_term])) . We then compare the cosine similarity of each encoded sentence with the encoded search term and rank the sentences accordingly. . results = cosine_similarity(encoded_query, encoded_text)[0] num_results = results.argsort()[-num_results:][::-1] scores = results[num_results] sentences = [input_text[idx] for idx in num_results] . Finally, we can print the list of five sentences that best match the search term. . print(&#39;*&#39;*30 + &#39; Start of output &#39; + &#39;*&#39;*30) printmd(&#39;**Search Results:**&#39;) for sentence, score in zip(sentences, scores): printmd(f&#39;* {sentence} (score: {score:&lt;.4f})&#39;) print(&#39;*&#39;*30 + &#39; End of output &#39; + &#39;*&#39;*30) . ****************************** Start of output ****************************** . Search Results: . Neural networks have been used for implementing language models since the early 2000s (score: 0.6076) | . Word embedding, such as , can be thought of as a representational layer in a deep learning architecture that transforms an atomic word into a positional representation of the word relative to other words in the dataset; the position is represented as a point in a (score: 0.5070) | . LSTM helped to improve machine translation and language modeling (score: 0.4982) | . A deep neural network (DNN) is an (ANN) with multiple layers between the input and output layers (score: 0.4969) | . An ANN is based on a collection of connected units called , (analogous to biological neurons in a ) (score: 0.4947) | . ****************************** End of output ****************************** . As you can see the output is fairly good and at least the top three sentences are highly relevant for our search. . In this demo we have seen that with just a few lines of code you can create a simple search engine that does whet it is supposed to do: it finds sentences from the source website/document that match our keyword. The same idea can be used in wide variety of use cases. . Hope you enjoyed this demo. Feel free to contact me if you have any questions. . Twitter: @AarneTalman | Website: talman.io | .",
            "url": "https://talman.io/information_retrieval/demo/2020/12/14/simple-semantic-search-engine-with-transformers.html",
            "relUrl": "/information_retrieval/demo/2020/12/14/simple-semantic-search-engine-with-transformers.html",
            "date": " • Dec 14, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Article Ranking with Natural Language Inference",
            "content": "In my previous post I showed how to fine-tune a pre-trained transformers model for the natural language inference (NLI) classification task. In this post I&#39;m taking a fine-tuned NLI model and use it to classify and rank articles in a news feed. . The idea is simple: we use an NLI model that has been trained on the MultiNLI task and pass an excerpt of the source text together with a search term we are interested in to the model. The model will then check if the source text entails the search term and returns a score. We can use these scores to rank the articles. We could use the model we trained on the previous demo, but luckily the people at Huggingface have made our lives much easier by releasing a new pipeline for zero-shot classification which uses a pre-trained NLI model. . So let&#39;s get started! First we need to install the required libraries and import them. In addition to the PyTorch and transformers libraries we are also installing and importing some libraries we need for retrieving and processing the news feeds and the articles. . !pip install transformers torch lxml bs4 feedparser . from transformers import pipeline, logging import torch import sys from bs4 import BeautifulSoup from bs4.element import Comment import requests import re import feedparser import time from operator import itemgetter from IPython.display import Markdown, display from tqdm import tqdm . logging.set_verbosity_error() . Next we will define some functions we need when we process html content retrieved from the websites. The text_from_html function uses BeautifulSoup to filter out unwanted content like html tags, comments, etc. We also define a function we will use to print out the results in markdown format. . def tag_visible(element): if element.parent.name in [&#39;p&#39;]: return True if isinstance(element, Comment): return False return False def text_from_html(html): soup = BeautifulSoup(html.content, &#39;lxml&#39;) texts = soup.findAll(text=True) visible_texts = filter(tag_visible, texts) return u&quot; &quot;.join(t.strip() for t in visible_texts) def printmd(string): display(Markdown(string)) . We need to define our classifier function that will take the source text and the search term and provide the result. The model we are using has a 1024 limit for the input text. Note that this will significantly impact the results as we might be cutting out some important information. However, for our demonstration purposes we will not care about this. You could of course split the text into smaller junks and perform classification of those junks separately and then combine the results at the end. . def classifier(source_text, search_term): src_text = source_text[:1024] classification = pipeline(&quot;zero-shot-classification&quot;, device=0) results = classification(src_text, search_term) return results . Now that we have defined our classifier function we have to define the news feed we want to retrieve the articles from. For this demo I want to understand what news releases have come out from Amazon Web Services (AWS) about machine learning in the past 7 days. So I&#39;m using AWS blog as the source and &quot;machine learning&quot; as the search term / classification label. We also define the number of articles we want to display. Let&#39;s say we want to see the top 4 articles about machine learning. . feed = &quot;https://aws.amazon.com/blogs/aws/feed/&quot; search_term = &quot;machine learning&quot; days = 7 number_of_articles = 4 . Next, we retrieve the newsfeed using the feedparser library. We then retrieve the html source for all the articles from the feed that have been published in the last 7 days. We use the text_from_html function to extract the text from the html source and call the classifier function. Finally, we save the classification score and other relevant information for each article. . newsfeed = feedparser.parse(feed) articles = [] entries = [entry for entry in newsfeed.entries if time.time() - time.mktime(entry.published_parsed) &lt; (86400*days)] for entry in tqdm(entries, total=len(entries)): html = requests.get(entry.link) src_text = text_from_html(html) # This is where we call our classifier function using the source text and the search term classification = classifier(src_text, search_term) article = dict() article[&quot;title&quot;] = entry.title article[&quot;link&quot;] = entry.link article[&quot;src_text&quot;] = src_text article[&quot;published&quot;] = entry.published_parsed article[&quot;relevancy&quot;] = classification[&quot;scores&quot;][0] articles.append(article) . 100%|██████████| 19/19 [07:39&lt;00:00, 24.16s/it] . Now that we have a list of classified articles we can sort them using the classification scores. . sorted_articles = sorted(articles, key=itemgetter(&quot;relevancy&quot;), reverse=True) . Before we display the results, I&#39;m defining another useful function that utilises the transformers summarization pipeline. We will use this function to create a short summary of each article on our list. . def summarise(source_text): src_text = source_text[:1024] summarization = pipeline(&quot;summarization&quot;) summary_text = summarization(src_text, min_length = 100)[0][&#39;summary_text&#39;] summary_text = re.sub(r&#39; s([?.!&quot;,](?: s|$))&#39;, r&#39; 1&#39;, summary_text) return summary_text . Finally, we can summarise the texts for our top 4 articles and print the results in a sorted order based on their ranking. . print(&#39;*&#39;*20 + &#39; Start of output &#39; + &#39;*&#39;*20) for article in sorted_articles[:number_of_articles]: summary = summarise(article[&quot;src_text&quot;]) printmd(&quot;**{}**&lt;br&gt;{}&lt;br&gt;{}&lt;br&gt;**Search term:** {} | **Score:** {:6.3f}&lt;br&gt;&lt;br&gt;&quot;.format(article[&quot;title&quot;], article[&quot;link&quot;], summary, search_term, 100*article[&quot;relevancy&quot;])) print(&#39;*&#39;*20 + &#39; End of output &#39; + &#39;*&#39;*20) . ******************** Start of output ******************** . New – Managed Data Parallelism in Amazon SageMaker Simplifies Training on Large Datasetshttps://aws.amazon.com/blogs/aws/managed-data-parallelism-in-amazon-sagemaker-simplifies-training-on-large-datasets/ Machine learning (ML) practitioners working on large distributed training jobs have to face increasingly long training times. Long training times are a severe bottleneck for ML projects, hurting productivity and slowing down innovation. SageMaker Data Parallelism (SDP) library now helps ML teams reduce distributed training time and cost, thanks to the SageMaker data parallelism library. It takes over 6 hours to train advanced object detection models such as Mask RCNN and Faster RCNN on the publicly available COCO dataset.Search term: machine learning | Score: 99.549 . Amazon SageMaker Simplifies Training Deep Learning Models With Billions of Parametershttps://aws.amazon.com/blogs/aws/amazon-sagemaker-simplifies-training-deep-learning-models-with-billions-of-parameters/ Deep learning (DL) has taken the world by storm in the last 10 years. Based on neural networks, DL algorithms have an extraordinary ability to extract information patterns hidden in vast amounts of unstructured data. DL has quickly achieved impressive results on a variety of complex human-like tasks, especially on computer vision and natural language processing. Today, I&#39;m extremely happy to announce that simplifies the training of very large deep learning models that were previously difficult to train due to hardware limitations. In order to tackle ever more complex tasks, DL researchers are designing increasingly sophisticated models.Search term: machine learning | Score: 99.120 . New – Amazon SageMaker Pipelines Brings DevOps Capabilities to your Machine Learning Projectshttps://aws.amazon.com/blogs/aws/amazon-sagemaker-pipelines-brings-devops-to-machine-learning-projects/ Machine learning (ML) is intrinsically experimental and unpredictable in nature. You spend days or weeks exploring and processing data in many different ways. Then, you experiment with different algorithms and parameters, training and optimizing lots of models in search of highest accuracy. Finally? Not quite, as you’ll certainly iterate again and again, either to try out new ideas, or simply to retrain your models on new data. Today, I’m extremely happy to announce a new capability of that makes it easy for data scientists and engineers to build, automate, and scale end to end machine learning pipelines.Search term: machine learning | Score: 98.130 . Amazon SageMaker JumpStart Simplifies Access to Pre-built Models and Machine Learning Solutionshttps://aws.amazon.com/blogs/aws/amazon-sagemaker-jumpstart-simplifies-access-to-prebuilt-models-and-machine-learning-models/ Machine learning (ML) has proven to be a valuable technique in improving and automating business processes. Working with these models requires skills and experience that only a subset of scientists and developers have. In order to simplify the model building process, the ML community has created model zoos, that is to say, collections of models built with popular open source librarie. Today, a capability of that accelerates your machine learning workflows with one-click access to popular model collections (also known as “model zoos”)Search term: machine learning | Score: 98.004 . ******************** End of output ******************** . There we have it: a working article ranker using a pre-trained NLI model. Super easy and fun! There are literally hundreds of use cases where these models and pipelines can be used to create useful applications. . Hope you enjoyed this demo. Feel free to contact me if you have any questions. . Twitter: @AarneTalman | Website: talman.io | .",
            "url": "https://talman.io/nli/pytorch/demo/2020/12/12/article-ranking-with-an-nli-model.html",
            "relUrl": "/nli/pytorch/demo/2020/12/12/article-ranking-with-an-nli-model.html",
            "date": " • Dec 12, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Natural Language Inference with PyTorch and Transformers",
            "content": "In this notebook I&#39;m showing how to use PyTorch and Huggingface Transformers to fine-tune a pre-trained transformers model to do natural language inference (NLI). In NLI the aim is to model the inferential relationship between two or more given sentences. In particular, given two sentences - the premise p and the hypothesis h - the task is to determine whether h is entailed by p, whether the sentences are in contradiction with each other or whether there is no inferential relationship between the sentences (neutral). . So let&#39;s get started! First we need to install the python libraries using the following command. . !pip3 install torch transformers datasets . We will then import the needed libraries. We are using DistilBERT model for this task so we need to import the relevant DistilBERT model designed for sequence classification task and the corresponding tokeniser. . import torch from torch.utils.data import DataLoader from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, AdamW, logging import datasets from tqdm import tqdm import numpy as np . logging.set_verbosity_error() . Let&#39;s load the MultiNLI dataset using the Huggingface Datasets library. For this demonstration we are using only the training and validation data. We are also further limiting the training data to just 20,000 sentence pairs. This will not allow us to train a good quality model, but it speeds up the demonstration. You can change the values here or use the whole dataset. However, be aware that fine tuning the model will take a lot of time. . nli_data = datasets.load_dataset(&quot;multi_nli&quot;) train_data = nli_data[&#39;train&#39;][:20000] # limiting the training set size to 20,000 for demo purposes train_labels = train_data[&#39;label&#39;] dev_data = nli_data[&#39;validation_matched&#39;] val_labels = dev_data[&#39;label&#39;] . Next we will initialise the tokeniser and tokenise our training and validation data. Notice that we are two lists of sentences to both the training and validation set. This is because in NLI we are classifying pairs of sentences: the premise and the hypothesis. . tokeniser = DistilBertTokenizerFast.from_pretrained(&#39;distilbert-base-uncased&#39;) train_encodings = tokeniser(train_data[&#39;premise&#39;], train_data[&#39;hypothesis&#39;], truncation=True, padding=True) val_encodings = tokeniser(dev_data[&#39;premise&#39;], dev_data[&#39;hypothesis&#39;], truncation=True, padding=True) . Once the data has been tokenised we will create a NLIDataset object for our data. Here we are creating a subclass that inherits the torch.utils.data.Dataset class. . class NLIDataset(torch.utils.data.Dataset): def __init__(self, encodings, labels): self.encodings = encodings self.labels = labels def __getitem__(self, idx): item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()} item[&#39;labels&#39;] = torch.tensor(self.labels[idx]) return item def __len__(self): return len(self.encodings.input_ids) . Once we&#39;ve defined our dataset class we can initialise the training and validation datasets with our tokenised sentence pairs and labels. We will then create DataLoader objects for the training and validation data. . train_dataset = NLIDataset(train_encodings, train_labels) val_dataset = NLIDataset(val_encodings, val_labels) train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True) val_loader = DataLoader(val_dataset, batch_size=16, shuffle=True) . Now, before we can start training, we need to import our model and optimiser to be used in training. We first set the device and use cuda if GPU is available. We then get the pre-trained DistilBERT model specifying the number of classes we are classifying to. . device = torch.device(&#39;cuda&#39;) if torch.cuda.is_available() else torch.device(&#39;cpu&#39;) model = DistilBertForSequenceClassification.from_pretrained(&#39;distilbert-base-uncased&#39;, num_labels=3) model.to(device) model.train() optim = AdamW(model.parameters(), lr=5e-5) . Now we are ready to train the model. In this demonstration we are fine-tuning for just three epochs, but you can change the value to something more meaningful if you like. Note that you could also use the Transformers Trainer class to fine-tune the model but I&#39;ve chosen to use native PyTorch instead. . epochs = 3 for epoch in range(epochs): all_losses = [] for batch in tqdm(train_loader, total=len(train_loader), desc=&quot;Epoch: {}/{}&quot;.format(epoch+1, epochs)): optim.zero_grad() input_ids = batch[&#39;input_ids&#39;].to(device) attention_mask = batch[&#39;attention_mask&#39;].to(device) labels = batch[&#39;labels&#39;].to(device) outputs = model(input_ids, attention_mask=attention_mask, labels=labels) loss = outputs[0] loss.backward() optim.step() all_losses.append(loss.item()) print(&quot; nMean loss: {:&lt;.4f}&quot;.format(np.mean(all_losses))) . Epoch: 1/3: 100%|██████████| 1250/1250 [15:31&lt;00:00, 1.34it/s] Epoch: 2/3: 0%| | 0/1250 [00:00&lt;?, ?it/s] . Mean loss: 0.8789 . Epoch: 2/3: 100%|██████████| 1250/1250 [15:27&lt;00:00, 1.35it/s] Epoch: 3/3: 0%| | 0/1250 [00:00&lt;?, ?it/s] . Mean loss: 0.5912 . Epoch: 3/3: 100%|██████████| 1250/1250 [15:27&lt;00:00, 1.35it/s] . Mean loss: 0.3316 . . Once the model has been trained we can evaluate it to get the validation accuracy for our model. . model.eval() with torch.no_grad(): eval_preds = [] eval_labels = [] for batch in tqdm(val_loader, total=len(val_loader)): input_ids = batch[&#39;input_ids&#39;].to(device) attention_mask = batch[&#39;attention_mask&#39;].to(device) labels = batch[&#39;labels&#39;].to(device) preds = model(input_ids, attention_mask=attention_mask, labels=labels) preds = preds[1].argmax(dim=-1) eval_preds.append(preds.cpu().numpy()) eval_labels.append(batch[&#39;labels&#39;].cpu().numpy()) print(&quot; nValidation accuracy: {:6.2f}&quot;.format(round(100 * (np.concatenate(eval_labels) == np.concatenate(eval_preds)).mean()), 2)) . 100%|██████████| 614/614 [02:26&lt;00:00, 4.18it/s] . Validation accuracy: 69.00 . . Now we are all done. As you can see the results are far from state of the art if you use just a fraction of the training data. . Hope you enjoyed this demo. Feel free to contact me if you have any questions. . Twitter: @AarneTalman | Website: talman.io | .",
            "url": "https://talman.io/nli/pytorch/demo/2020/12/11/natural-language-inference-with-pytorch-and-transformers.html",
            "relUrl": "/nli/pytorch/demo/2020/12/11/natural-language-inference-with-pytorch-and-transformers.html",
            "date": " • Dec 11, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About",
          "content": "See my full CV or find me on LinkedIn. . Education . 2018 - present, PhD in Language Technology, University of Helsinki | 2005 - 2007, MSc in Computational Linguistics and Formal Grammar, King’s College London Graduated with Distinction. | 2002 - 2005, BSc in Philosophy, London School of Economics Graduated with First Class Honours. | . Employment . 2020 - present, CTO, Nordcloud UK | 2018 - 2020, Doctoral Researcher, Language Technology, University of Helsinki Working on computational semantics and natural language processing. | 2019 - present, Founder, Basement AI Basement AI is a Nordic artificial intelligence research lab specializing in natural language processing and machine learning. | 2015 - 2018, Associate Director, Consulting, Gartner. | 2012 - 2015, Consultant, Accenture. | 2011 - 2012, Research Student, London School of Economics. | 2009 - 2011, Product Manager, Nokia. | 2008 - 2009, Manager, Nokia. | 2006 - 2008, Systems Analyst, Tieto. | 2006 - 2006, Software Developer, Valuatum. | .",
          "url": "https://talman.io/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  
      ,"page2": {
          "title": "Code",
          "content": "Code . Prosody: A system for predicting prosodic prominence from written text. License: MIT | Paper | . | Natural Language Inference: Natural language inference system written in Python and PyTorch implementing the HBMP sentence encoder. License: MIT | Paper | . | NLP Notebooks: Jupyter notebooks exploring different NLP/ML use cases and tasks. | NLI with Transformers: Code for fine-tuning different transformers models with NLI data. | Data . Helsinki Prosody Corpus: The prosody corpus contains automatically generated, high quality prosodic annotations for the LibriTTS corpus (Zen et al. 2019) using the Continuous Wavelet Transform Annotation method (Suni et al. 2017). Language: English | License: CC BY 4.0 | Paper | . |",
          "url": "https://talman.io/code/",
          "relUrl": "/code/",
          "date": ""
      }
      
  

  

  
      ,"page4": {
          "title": "Publications and Talks",
          "content": "Academic Publications . See my Google Scholar profile. . Aarne Talman, Antti Suni, Hande Celikkanat, Sofoklis Kakouros, Jörg Tiedemann and Martti Vainio. 2019. Predicting Prosodic Prominence from Text with Pre-trained Contextualized Word Representations. Proceedings of NoDaLiDa 2019. [bibtex] [pdf] [corpus and code] | Aarne Talman, Umut Sulubacak, Raúl Vázquez, Yves Scherrer, Sami Virpioja, Alessandro Raganato, Arvi Hurskainen, and Jörg Tiedemann. 2019. The University of Helsinki submissions to the WMT19 news translation task. Proceedings of the Fourth Conference on Machine Translation: Shared Task Papers. [bibtex] [pdf] | Aarne Talman and Stergios Chatzikyriakidis. 2019. Testing the Generalization Power of Neural Network Models Across NLI Benchmarks. Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP. [bibtex] [pdf] | Aarne Talman, Anssi Yli-Jyrä and Jörg Tiedemann. 2019. Sentence Embeddings in NLI with Iterative Refinement Encoders. Natural Language Engineering 25(4). [bibtex] [pdf] [code] | Academic Talks . Predicting Prosodic Prominence from Text with Pre-trained Contextualized Word Representations. 14 November 2019, Research Seminar in Language Technology, University of Helsinki. [pdf] | Predicting Prosodic Prominence from Text with Pre-trained Contextualized Word Representations. 2 October 2019, NoDaLiDa 2019, Turku. [pdf] | Neural Network models of NLI fail to capture the general notion of inference, 8 March 2019, CLASP Seminar, University of Gothenburg. [pdf] | State-of-the-Art Natural Language Inference Systems Fail to Capture the Semantics of Inference, 25 October 2018, Research Seminar in Language Technology, University of Helsinki. [pdf] | Natural Language Inference with Hierarchical BiLSTM’s, 28 September 2018, FoTran 2018. [pdf] | Natural Language Inference - Another Triumph for Deep Learning?, 23 November 2017, Research Seminar in Language Technology, University of Helsinki. [pdf] |",
          "url": "https://talman.io/publications/",
          "relUrl": "/publications/",
          "date": ""
      }
      
  

  
  

  

  
  

  

  
      ,"page9": {
          "title": "Teaching",
          "content": "University of Helsinki . Instructor: Natural Language Understanding and Representation Learning. Spring 2020. | Supervision: Learning and evaluation of multilingual sentence representations (Master Thesis) | Reading Group: Representation Learning for Natural Language Understanding. Autumn 2019. | Teaching Assistant: KIK-LG210 Machine Learning for Linguists. Spring 2019. | Teaching Assistant: LDA-T3115 A Practical Introduction to Modern Neural Machine Translation. Spring 2019. | . Other . Lab monitor / TA: 2019 Lisbon Machine Learning School (LxMLS 2019). | .",
          "url": "https://talman.io/teaching/",
          "relUrl": "/teaching/",
          "date": ""
      }
      
  

  
  

  
  

  
  

  
      ,"page13": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://talman.io/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}