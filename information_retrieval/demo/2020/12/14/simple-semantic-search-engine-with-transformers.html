<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Semantic Search with Pre-trained Sentence Encoders | Aarne Talman</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Semantic Search with Pre-trained Sentence Encoders" />
<meta name="author" content="Aarne Talman" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Demo on how to build a simple semantic search engine with pre-trained transformer models" />
<meta property="og:description" content="Demo on how to build a simple semantic search engine with pre-trained transformer models" />
<link rel="canonical" href="https://talman.io/information_retrieval/demo/2020/12/14/simple-semantic-search-engine-with-transformers.html" />
<meta property="og:url" content="https://talman.io/information_retrieval/demo/2020/12/14/simple-semantic-search-engine-with-transformers.html" />
<meta property="og:site_name" content="Aarne Talman" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-12-14T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"https://talman.io/information_retrieval/demo/2020/12/14/simple-semantic-search-engine-with-transformers.html","@type":"BlogPosting","headline":"Semantic Search with Pre-trained Sentence Encoders","dateModified":"2020-12-14T00:00:00-06:00","datePublished":"2020-12-14T00:00:00-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://talman.io/information_retrieval/demo/2020/12/14/simple-semantic-search-engine-with-transformers.html"},"author":{"@type":"Person","name":"Aarne Talman"},"description":"Demo on how to build a simple semantic search engine with pre-trained transformer models","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://talman.io/feed.xml" title="Aarne Talman" /><!-- the google_analytics_id gets auto inserted from the config file -->


<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-KNGC46YL32"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-KNGC46YL32');
</script>
<!--<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','G-KNGC46YL32','auto');ga('require','displayfeatures');ga('send','pageview');</script>-->

<link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Aarne Talman</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a><a class="page-link" href="/code/">Code</a><a class="page-link" href="/publications/">Publications and Talks</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a><a class="page-link" href="/teaching/">Teaching</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Semantic Search with Pre-trained Sentence Encoders</h1><p class="page-description">Demo on how to build a simple semantic search engine with pre-trained transformer models</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-12-14T00:00:00-06:00" itemprop="datePublished">
        Dec 14, 2020
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Aarne Talman</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      4 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#information_retrieval">information_retrieval</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#demo">demo</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/aarnetalman/blog/tree/master/_notebooks/2020-12-14-simple-semantic-search-engine-with-transformers.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          
          <div class="px-2">
    <a href="https://colab.research.google.com/github/aarnetalman/blog/blob/master/_notebooks/2020-12-14-simple-semantic-search-engine-with-transformers.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-12-14-simple-semantic-search-engine-with-transformers.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the previous two posts I've explored the <a href="https://github.com/huggingface/transformers">HuggingFace Transformers</a> library and demonstrated:</p>
<ol>
<li><p>how to <a href="https://talman.io/nli/pytorch/demo/2020/12/11/natural-language-inference-with-pytorch-and-transformers.html">train a classification model for NLI</a></p>
</li>
<li><p>how to use an NLI model to <a href="https://talman.io/nli/pytorch/demo/2020/12/12/article-ranking-with-an-nli-model.html">rank news articles</a> based on a keyword</p>
</li>
</ol>
<p>In this post I will show how to use a pre-trained sentence encoder model to create a simple semantic search engine for website content. The search engine will be "semantic" in the sense that it will try to find sentences from the website whose vector representation "matches" the vector representation of the search term.</p>
<p>We will use a pre-trained transformers model to encode all the sentences of a website as well as the search term and then calculate the <a href="https://en.wikipedia.org/wiki/Cosine_similarity">cosine similarity</a> between each encoded sentence and the search term. We will then rank the sentences based on the cosine similarity.</p>
<p>Let's get started. As before we will first install the libraries we need for this demo. We are using a library called <a href="https://github.com/UKPLab/sentence-transformers">Sentence Transformers</a>, which provides pre-trained transformers models specifically for the purpose of computing sentence-level vector representations. We also need to install scikit-learn, as we will use it to calculate the cosine similarities between sentence vectors.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install sentence_transformers sklearn lxml bs4
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Once we have installed the liraries we will import them together with some other usefult librarires we will use in the demo.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sentence_transformers</span> <span class="kn">import</span> <span class="n">SentenceTransformer</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">from</span> <span class="nn">bs4.element</span> <span class="kn">import</span> <span class="n">Comment</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Markdown</span><span class="p">,</span> <span class="n">display</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As in the previous post we define some functions we will use for cleaning up the text from the website html as well as a function to print our output in markdown format.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">tag_visible</span><span class="p">(</span><span class="n">element</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">element</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;p&#39;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">element</span><span class="p">,</span> <span class="n">Comment</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="kc">False</span>

<span class="k">def</span> <span class="nf">text_from_html</span><span class="p">(</span><span class="n">html</span><span class="p">):</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">html</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="s1">&#39;lxml&#39;</span><span class="p">)</span>
    <span class="n">texts</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">findAll</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">visible_texts</span> <span class="o">=</span> <span class="nb">filter</span><span class="p">(</span><span class="n">tag_visible</span><span class="p">,</span> <span class="n">texts</span><span class="p">)</span>  
    <span class="k">return</span> <span class="sa">u</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">visible_texts</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">printmd</span><span class="p">(</span><span class="n">string</span><span class="p">):</span>
    <span class="n">display</span><span class="p">(</span><span class="n">Markdown</span><span class="p">(</span><span class="n">string</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we can define the website we are interested in together with the search term. We also define how many search results we want to see. In this demo we are interested in finding top five sentences from the Deep Learning Wikipedia article that are about Natural Language Processing.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">website</span> <span class="o">=</span> <span class="s1">&#39;https://en.wikipedia.org/wiki/Deep_learning&#39;</span>
<span class="n">search_term</span> <span class="o">=</span> <span class="s1">&#39;natural language processing&#39;</span>
<span class="n">num_results</span> <span class="o">=</span> <span class="mi">5</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We then retrieve and extract the text from the website and split the sentences to a list.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">html</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">website</span><span class="p">)</span>             
<span class="n">src_text</span> <span class="o">=</span> <span class="n">text_from_html</span><span class="p">(</span><span class="n">html</span><span class="p">)</span>
<span class="n">input_text</span> <span class="o">=</span> <span class="n">src_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For our model we use the <code>roberta-large-nli-stsb-mean-tokens</code> model which according to the <a href="https://github.com/UKPLab/sentence-transformers">Sentence transformers Github page</a> beats the other Sentence Transformer models in the Semantic Textual Similarity (STS) benchmark.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="s1">&#39;roberta-base-nli-stsb-mean-tokens&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next we encode the list of sentences retrieved from the website as well as the search term using the Sentence Transformer model.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">encoded_text</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">input_text</span><span class="p">))</span>
<span class="n">encoded_query</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">([</span><span class="n">search_term</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We then compare the cosine similarity of each encoded sentence with the encoded search term and rank the sentences accordingly.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">encoded_query</span><span class="p">,</span> <span class="n">encoded_text</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">num_results</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">argsort</span><span class="p">()[</span><span class="o">-</span><span class="n">num_results</span><span class="p">:][::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="n">num_results</span><span class="p">]</span>
<span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="n">input_text</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">num_results</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally, we can print the list of five sentences that best match the search term.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">30</span> <span class="o">+</span> <span class="s1">&#39; Start of output &#39;</span> <span class="o">+</span> <span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">30</span><span class="p">)</span>
<span class="n">printmd</span><span class="p">(</span><span class="s1">&#39;**Search Results:**&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">sentence</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">scores</span><span class="p">):</span>
    <span class="n">printmd</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;* </span><span class="si">{</span><span class="n">sentence</span><span class="si">}</span><span class="s1"> (score: </span><span class="si">{</span><span class="n">score</span><span class="si">:</span><span class="s1">&lt;.4f</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">30</span> <span class="o">+</span> <span class="s1">&#39; End of output &#39;</span> <span class="o">+</span> <span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">30</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>****************************** Start of output ******************************
</pre>
</div>
</div>

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<p><strong>Search Results:</strong></p>

</div>

</div>

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<ul>
<li>Neural networks have been used for implementing language models since the early 2000s (score: 0.6076)</li>
</ul>

</div>

</div>

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<ul>
<li>Word embedding, such as , can be thought of as a representational layer in a deep learning architecture that transforms an atomic word into a positional representation of the word relative to other words in the dataset; the position is represented as a point in a  (score: 0.5070)</li>
</ul>

</div>

</div>

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<ul>
<li>LSTM helped to improve machine translation and language modeling (score: 0.4982)</li>
</ul>

</div>

</div>

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<ul>
<li>A deep neural network (DNN) is an (ANN) with multiple layers between the input and output layers (score: 0.4969)</li>
</ul>

</div>

</div>

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<ul>
<li>An ANN is based on a collection of connected units called , (analogous to biological neurons in a ) (score: 0.4947)</li>
</ul>

</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>****************************** End of output ******************************
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As you can see the output is fairly good and at least the top three sentences are highly relevant for our search.</p>
<p>In this demo we have seen that with just a few lines of code you can create a simple search engine that does whet it is supposed to do: it finds sentences from the source website/document that match our keyword. The same idea can be used in wide variety of use cases.</p>
<p>Hope you enjoyed this demo. Feel free to contact me if you have any questions.</p>
<ul>
<li>Twitter: <a href="https://twitter.com/aarnetalman">@AarneTalman</a></li>
<li>Website: <a href="https://talman.io">talman.io</a></li>
</ul>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="aarnetalman/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/information_retrieval/demo/2020/12/14/simple-semantic-search-engine-with-transformers.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Natural Language Processing and Machine Learning</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/aarnetalman" title="aarnetalman"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/aarnetalman" title="aarnetalman"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
